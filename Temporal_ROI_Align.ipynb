{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samruddhishastri/nerve-detection/blob/main/Temporal_ROI_Align.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab2c382c-a169-46fe-938f-c6687d763e8e"
      },
      "source": [
        "## **Install MMTracking**"
      ],
      "id": "ab2c382c-a169-46fe-938f-c6687d763e8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
        "outputId": "7e7fc391-6c41-47b5-f469-5a1594d2d99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
        "outputId": "0ce21c93-e380-4580-d232-256957b2189c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (46.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.4 MB 25.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.5.2 yapf-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-2.25.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet) (4.2.0)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-2.25.0 terminaltables-3.1.10\n",
            "Cloning into 'mmtracking'...\n",
            "remote: Enumerating objects: 4451, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 4451 (delta 53), reused 125 (delta 28), pack-reused 4274\u001b[K\n",
            "Receiving objects: 100% (4451/4451), 1.90 MiB | 21.82 MiB/s, done.\n",
            "Resolving deltas: 100% (2612/2612), done.\n",
            "/content/mmtracking\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 1)) (0.29.30)\n",
            "Collecting numba==0.53.0\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53.0->-r requirements/build.txt (line 2)) (57.4.0)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.36.0 numba-0.53.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmtracking\n",
            "Collecting attributee==0.1.5\n",
            "  Downloading attributee-0.1.5.tar.gz (11 kB)\n",
            "Collecting dotty_dict\n",
            "  Downloading dotty_dict-1.3.0.tar.gz (32 kB)\n",
            "Collecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (3.2.2)\n",
            "Collecting mmcls>=0.16.0\n",
            "  Downloading mmcls-0.23.1-py2.py3-none-any.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 64.8 MB/s \n",
            "\u001b[?25hCollecting motmetrics\n",
            "  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 76.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (4.1.2.30)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (21.3)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (1.3.5)\n",
            "Collecting pycocotools<=2.0.2\n",
            "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
            "Requirement already satisfied: scipy<=1.7.3 in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (0.11.2)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcls>=0.16.0->mmtrack==0.13.0) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==0.13.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==0.13.0) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools<=2.0.2->mmtrack==0.13.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools<=2.0.2->mmtrack==0.13.0) (0.29.30)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmtrack==0.13.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<=1.3.5->mmtrack==0.13.0) (1.15.0)\n",
            "Collecting setuptools_scm\n",
            "  Downloading setuptools_scm-6.4.2-py3-none-any.whl (37 kB)\n",
            "Collecting xmltodict>=0.12.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from setuptools_scm->dotty_dict->mmtrack==0.13.0) (2.0.1)\n",
            "Building wheels for collected packages: attributee, pycocotools, dotty-dict, lap\n",
            "  Building wheel for attributee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attributee: filename=attributee-0.1.5-py3-none-any.whl size=12076 sha256=157d41ca907ff7b6438465f1a602437e66d40dba1df36dc68d877a9713e18ca5\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/12/3a/b7e98eb4e3d373862bf9f160f77171b72a3825c4867064d8b2\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=265270 sha256=dacc6286e65f13d651f8337670b1b9128fdb3f43fb103e3e6a9755bb2bf29b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\n",
            "  Building wheel for dotty-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dotty-dict: filename=dotty_dict-1.3.0-py3-none-any.whl size=7682 sha256=4bda7739e45def11910f20288a6550bda5999d58a268e8d434d00f786f48062e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/13/9a/3c1bbc95fedfbcb79816e33fd6439fdccf111aeea1b9be6640\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1590231 sha256=353de245f9fecc2a1121e7f5e23fa8758060b8aed7fdb08532d81624bae635da\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n",
            "Successfully built attributee pycocotools dotty-dict lap\n",
            "Installing collected packages: xmltodict, setuptools-scm, pycocotools, motmetrics, mmcls, lap, dotty-dict, attributee, mmtrack\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.4\n",
            "    Uninstalling pycocotools-2.0.4:\n",
            "      Successfully uninstalled pycocotools-2.0.4\n",
            "  Running setup.py develop for mmtrack\n",
            "Successfully installed attributee-0.1.5 dotty-dict-1.3.0 lap-0.4.0 mmcls-0.23.1 mmtrack-0.13.0 motmetrics-1.2.5 pycocotools-2.0.2 setuptools-scm-6.4.2 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "# install MMCV\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
        "\n",
        "# install MMDetection\n",
        "!pip install mmdet\n",
        "\n",
        "# clone the MMTracking repository\n",
        "!git clone https://github.com/open-mmlab/mmtracking.git\n",
        "%cd mmtracking\n",
        "\n",
        "# install MMTracking and its dependencies\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -e ."
      ],
      "id": "6b4f093f-e197-42bd-ba64-dc905e379382"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
        "outputId": "f5c8db19-a4b4-471a-e83a-29595351eb15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CUDA available': True,\n",
              " 'CUDA_HOME': '/usr/local/cuda',\n",
              " 'GCC': 'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0',\n",
              " 'GPU 0': 'Tesla T4',\n",
              " 'MMCV': '1.5.2',\n",
              " 'MMCV CUDA Compiler': '11.1',\n",
              " 'MMCV Compiler': 'GCC 7.3',\n",
              " 'NVCC': 'Cuda compilation tools, release 11.1, V11.1.105',\n",
              " 'OpenCV': '4.1.2',\n",
              " 'PyTorch': '1.11.0+cu113',\n",
              " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.3\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.2\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \\n',\n",
              " 'Python': '3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]',\n",
              " 'TorchVision': '0.12.0+cu113',\n",
              " 'sys.platform': 'linux'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ],
      "id": "03a4a583-78e7-40a1-a6ef-d80056989546"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
        "outputId": "8eee6c4c-aba5-47c6-b913-8835b4f62867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113 True\n",
            "11.1\n",
            "GCC 7.3\n",
            "2.25.0\n",
            "0.13.0\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check MMTracking installation\n",
        "import mmtrack\n",
        "print(mmtrack.__version__)"
      ],
      "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Oo59535xMV8",
        "outputId": "c8a23854-9707-4779-9346-90d04f3fadde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "_Oo59535xMV8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29"
      },
      "source": [
        "## **Train a Temporal ROI Align model with a Nerve dataset**"
      ],
      "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5"
      },
      "source": [
        "### **Prepare dataset**"
      ],
      "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!unzip -q /content/drive/MyDrive/Colab\\ Notebooks/youtubevis.zip -d ./data"
      ],
      "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
        "outputId": "325d4263-74de-4172-b403-7d059a6f0ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/mmtracking/tools/convert_datasets/youtubevis/youtubevis2coco.py': No such file or directory\n",
            "1934\n",
            "/content/mmtracking/data/binary2coco.py:116: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  area_val = np.int(np.sum(annot_file))\n",
            "7323\n",
            "5946\n",
            "8789\n",
            "8917\n",
            "3241\n",
            "8505\n",
            "1245\n",
            "9270\n",
            "7026\n",
            "4555\n",
            "4374\n",
            "8979\n",
            "8117\n",
            "6208\n",
            "3072\n",
            "9452\n",
            "1595\n",
            "6637\n",
            "2595\n",
            "9325\n",
            "8674\n",
            "4680\n",
            "7564\n",
            "3938\n",
            "7001\n",
            "9814\n",
            "7693\n",
            "7202\n",
            "9092\n",
            "1081\n",
            "2416\n",
            "6039\n",
            "1861\n",
            "2002\n",
            "5088\n",
            "1592\n",
            "1032\n",
            "3965\n",
            "5030\n",
            "1104\n",
            "6168\n",
            "2388\n",
            "4927\n",
            "2706\n",
            "4628\n",
            "8884\n",
            "2654\n",
            "4022\n",
            "2724\n",
            "2704\n",
            "9344\n",
            "4605\n",
            "4981\n",
            "5865\n",
            "2596\n",
            "7704\n",
            "4064\n",
            "8903\n",
            "2082\n",
            "9075\n",
            "1302\n",
            "4344\n",
            "4277\n",
            "9299\n",
            "9106\n",
            "4969\n",
            "6542\n",
            "4192\n",
            "6802\n",
            "1433\n",
            "2755\n",
            "4971\n",
            "9005\n",
            "6282\n",
            "4656\n",
            "4096\n",
            "9415\n",
            "4296\n",
            "8241\n",
            "2565\n",
            "9012\n",
            "4578\n",
            "5452\n",
            "9847\n",
            "2201\n",
            "7692\n",
            "5850\n",
            "9641\n",
            "2014\n",
            "6485\n",
            "5649\n",
            "8896\n",
            "2848\n",
            "8386\n",
            "2753\n",
            "1719\n",
            "8988\n",
            "8779\n",
            "5247\n",
            "2293\n",
            "4764\n",
            "5058\n",
            "6908\n",
            "1811\n",
            "6185\n",
            "4215\n",
            "4103\n",
            "7008\n",
            "1483\n",
            "6997\n",
            "1490\n",
            "2622\n",
            "/content/mmtracking/data/binary2coco.py:116: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  area_val = np.int(np.sum(annot_file))\n",
            "9101\n",
            "5749\n",
            "2443\n",
            "9875\n",
            "2940\n",
            "6701\n",
            "1356\n",
            "2237\n",
            "7726\n",
            "8365\n",
            "7048\n",
            "6674\n",
            "6422\n",
            "3161\n",
            "3015\n",
            "8510\n",
            "4891\n",
            "8018\n"
          ]
        }
      ],
      "source": [
        "# convert the dataset to coco format\n",
        "!rm /content/mmtracking/tools/convert_datasets/youtubevis/youtubevis2coco.py\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/binary2coco.py /content/mmtracking/data\n",
        "!mkdir /content/mmtracking/data/youtubevis/annotations_coco\n",
        "!python /content/mmtracking/data/binary2coco.py /content/mmtracking/data/youtubevis/train /content/mmtracking/data/youtubevis/annot_imgs /content/mmtracking/data/youtubevis/annotations_coco train\n",
        "!python /content/mmtracking/data/binary2coco.py /content/mmtracking/data/youtubevis/valid /content/mmtracking/data/youtubevis/annot_imgs_valid /content/mmtracking/data/youtubevis/annotations_coco valid\n"
      ],
      "id": "d0db0d5f-b192-48ee-b145-149f33ad3685"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae887970-7382-4bd0-a739-6b07e6dded6f"
      },
      "source": [
        "### **Train a detector for TROIA**"
      ],
      "id": "ae887970-7382-4bd0-a739-6b07e6dded6f"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/mmtracking/configs/vid/temporal_roi_align/selsa_troialign_faster_rcnn_r50_dc5_7e_imagenetvid.py /content/mmtracking/configs/vid/temporal_roi_align/selsa_troialign_faster_rcnn_r50_dc5_7e_imagenetvid_copy.py"
      ],
      "metadata": {
        "id": "vnm6RRjiOW-X"
      },
      "id": "vnm6RRjiOW-X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "cfg = mmcv.Config.fromfile('/content/mmtracking/configs/vid/temporal_roi_align/selsa_troialign_faster_rcnn_r50_dc5_7e_imagenetvid_copy.py')"
      ],
      "metadata": {
        "id": "gwMYeLrzN0NJ"
      },
      "id": "gwMYeLrzN0NJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
        "outputId": "2e8c0c3e-ed26-4f8b-cb77-ebad992e262b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(3, ),\n",
            "            strides=(1, 2, 2, 1),\n",
            "            dilations=(1, 1, 1, 2),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            style='pytorch',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "        neck=dict(\n",
            "            type='ChannelMapper',\n",
            "            in_channels=[2048],\n",
            "            out_channels=512,\n",
            "            kernel_size=3),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=512,\n",
            "            feat_channels=512,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[4, 8, 16, 32],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[16]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(\n",
            "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
            "                loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='SelsaRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='TemporalRoIAlign',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "                out_channels=512,\n",
            "                featmap_strides=[16],\n",
            "                num_most_similar_points=2,\n",
            "                num_temporal_attention_blocks=4),\n",
            "            bbox_head=dict(\n",
            "                type='SelsaBBoxHead',\n",
            "                in_channels=512,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=1,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.2, 0.2, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0),\n",
            "                num_shared_fcs=3,\n",
            "                aggregator=dict(\n",
            "                    type='SelsaAggregator',\n",
            "                    in_channels=1024,\n",
            "                    num_attention_blocks=16))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=0,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=6000,\n",
            "                max_per_img=600,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=6000,\n",
            "                max_per_img=300,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.0001,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100))),\n",
            "    type='SELSA')\n",
            "dataset_type = 'CocoVideoDataset'\n",
            "data_root = '/content/mmtracking/data/youtubevis'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadMultiImagesFromFile'),\n",
            "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
            "    dict(type='SeqResize', img_scale=(1000, 600), keep_ratio=True),\n",
            "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='SeqNormalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='SeqPad', size_divisor=16),\n",
            "    dict(\n",
            "        type='VideoCollect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_instance_ids']),\n",
            "    dict(type='ConcatVideoReferences'),\n",
            "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadMultiImagesFromFile'),\n",
            "    dict(type='SeqResize', img_scale=(1000, 600), keep_ratio=True),\n",
            "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.0),\n",
            "    dict(\n",
            "        type='SeqNormalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='SeqPad', size_divisor=16),\n",
            "    dict(\n",
            "        type='VideoCollect',\n",
            "        keys=['img'],\n",
            "        meta_keys=('num_left_ref_imgs', 'frame_stride')),\n",
            "    dict(type='ConcatVideoReferences'),\n",
            "    dict(type='MultiImagesToTensor', ref_prefix='ref'),\n",
            "    dict(type='ToList')\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoVideoDataset',\n",
            "        ann_file=\n",
            "        '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_train.json',\n",
            "        img_prefix='/content/mmtracking/data/youtubevis/train',\n",
            "        ref_img_sampler=None,\n",
            "        pipeline=[\n",
            "            dict(type='LoadMultiImagesFromFile'),\n",
            "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
            "            dict(type='SeqResize', img_scale=(1000, 600), keep_ratio=True),\n",
            "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='SeqNormalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='SeqPad', size_divisor=16),\n",
            "            dict(\n",
            "                type='VideoCollect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_instance_ids']),\n",
            "            dict(type='ConcatVideoReferences'),\n",
            "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
            "        ],\n",
            "        classes=['nerve']),\n",
            "    val=dict(\n",
            "        type='CocoVideoDataset',\n",
            "        ann_file=\n",
            "        '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_valid.json',\n",
            "        img_prefix='/content/mmtracking/data/youtubevis/valid',\n",
            "        ref_img_sampler=dict(\n",
            "            num_ref_imgs=14,\n",
            "            frame_range=[-7, 7],\n",
            "            method='test_with_adaptive_stride'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadMultiImagesFromFile'),\n",
            "            dict(type='SeqResize', img_scale=(1000, 600), keep_ratio=True),\n",
            "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.0),\n",
            "            dict(\n",
            "                type='SeqNormalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='SeqPad', size_divisor=16),\n",
            "            dict(\n",
            "                type='VideoCollect',\n",
            "                keys=['img'],\n",
            "                meta_keys=('num_left_ref_imgs', 'frame_stride')),\n",
            "            dict(type='ConcatVideoReferences'),\n",
            "            dict(type='MultiImagesToTensor', ref_prefix='ref'),\n",
            "            dict(type='ToList')\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        classes=['nerve']),\n",
            "    test=dict(\n",
            "        type='CocoVideoDataset',\n",
            "        ann_file=\n",
            "        '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_test.json',\n",
            "        img_prefix='/content/mmtracking/data/youtubevis/test',\n",
            "        ref_img_sampler=dict(\n",
            "            num_ref_imgs=14,\n",
            "            frame_range=[-7, 7],\n",
            "            method='test_with_adaptive_stride'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadMultiImagesFromFile'),\n",
            "            dict(type='SeqResize', img_scale=(1000, 600), keep_ratio=True),\n",
            "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.0),\n",
            "            dict(\n",
            "                type='SeqNormalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='SeqPad', size_divisor=16),\n",
            "            dict(\n",
            "                type='VideoCollect',\n",
            "                keys=['img'],\n",
            "                meta_keys=('num_left_ref_imgs', 'frame_stride')),\n",
            "            dict(type='ConcatVideoReferences'),\n",
            "            dict(type='MultiImagesToTensor', ref_prefix='ref'),\n",
            "            dict(type='ToList')\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        classes=['nerve']))\n",
            "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[2, 5])\n",
            "total_epochs = 7\n",
            "evaluation = dict(metric=['bbox'], interval=7)\n",
            "work_dir = './tutorial_exps/detector'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "device = 'cuda'\n",
            "classes = ['nerve']\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9903"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "\n",
        "cfg.data_root = '/content/mmtracking/data/youtubevis'\n",
        "cfg.data.test.ann_file = '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_test.json'\n",
        "cfg.data.train[0].ann_file = '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_train.json'\n",
        "cfg.data.val.ann_file = '/content/mmtracking/data/youtubevis/annotations_coco/youtube_vis_2019_valid.json'\n",
        "\n",
        "cfg.data.test.img_prefix = '/content/mmtracking/data/youtubevis/test'\n",
        "cfg.data.train[0].img_prefix = '/content/mmtracking/data/youtubevis/train'\n",
        "cfg.data.val.img_prefix = '/content/mmtracking/data/youtubevis/valid'\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/detector'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.model.detector.roi_head.bbox_head.num_classes = 1\n",
        "cfg.data.train = cfg.data.train[0]\n",
        "cfg.device='cuda'\n",
        "\n",
        "cfg.classes = ['nerve']\n",
        "cfg.dataset_type = 'CocoVideoDataset'\n",
        "cfg.data.train.type = 'CocoVideoDataset'\n",
        "cfg.data.train.classes = ['nerve']\n",
        "cfg.data.val.type = 'CocoVideoDataset'\n",
        "cfg.data.val.classes = ['nerve']\n",
        "cfg.data.test.type = 'CocoVideoDataset'\n",
        "cfg.data.test.classes = ['nerve']\n",
        "\n",
        "cfg.data.train.ref_img_sampler = None\n",
        "# cfg.data.val.ref_img_sampler = None\n",
        "# cfg.data.test.ref_img_sampler = None\n",
        "\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "file1 = open('/content/mmtracking/configs/vid/temporal_roi_align/new_config.py', 'w+')\n",
        "file1.write(cfg.pretty_text)"
      ],
      "id": "bce04095-8586-45c5-a556-40c51d08b2cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
        "outputId": "4dfaf0e7-b308-47a8-aab4-b08ced8b7a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-13 18:39:12,362 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
            "2022-06-13 18:39:12,363 - mmcv - INFO - load model from: torchvision://resnet50\n",
            "2022-06-13 18:39:12,366 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
            "2022-06-13 18:39:12,472 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "2022-06-13 18:39:12,505 - mmcv - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
            "2022-06-13 18:39:12,571 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
            "2022-06-13 18:39:12,607 - mmcv - INFO - initialize SelsaBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2022-06-13 18:39:12,857 - mmcv - INFO - \n",
            "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,859 - mmcv - INFO - \n",
            "backbone.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,860 - mmcv - INFO - \n",
            "backbone.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,866 - mmcv - INFO - \n",
            "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,869 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,871 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,874 - mmcv - INFO - \n",
            "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,875 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,887 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,889 - mmcv - INFO - \n",
            "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,891 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,894 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,898 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,900 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,903 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,904 - mmcv - INFO - \n",
            "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,906 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,908 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,909 - mmcv - INFO - \n",
            "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,911 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,912 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,913 - mmcv - INFO - \n",
            "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,915 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,916 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,918 - mmcv - INFO - \n",
            "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,919 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,920 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,922 - mmcv - INFO - \n",
            "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,923 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,925 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,926 - mmcv - INFO - \n",
            "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,928 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,929 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,931 - mmcv - INFO - \n",
            "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,933 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,937 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,938 - mmcv - INFO - \n",
            "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,940 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,941 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,942 - mmcv - INFO - \n",
            "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,944 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,945 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,947 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,953 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,954 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,955 - mmcv - INFO - \n",
            "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,956 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,958 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,960 - mmcv - INFO - \n",
            "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,961 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,963 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,965 - mmcv - INFO - \n",
            "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,966 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,968 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,970 - mmcv - INFO - \n",
            "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,971 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,973 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,974 - mmcv - INFO - \n",
            "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,976 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,978 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,979 - mmcv - INFO - \n",
            "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,981 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,982 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,984 - mmcv - INFO - \n",
            "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,985 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,987 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,989 - mmcv - INFO - \n",
            "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,990 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,992 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,993 - mmcv - INFO - \n",
            "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,994 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,995 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,997 - mmcv - INFO - \n",
            "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:12,999 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,000 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,001 - mmcv - INFO - \n",
            "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,003 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,005 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,006 - mmcv - INFO - \n",
            "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,009 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,011 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,012 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,013 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,015 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,016 - mmcv - INFO - \n",
            "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,017 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,019 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,020 - mmcv - INFO - \n",
            "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,021 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,023 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,024 - mmcv - INFO - \n",
            "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,026 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,027 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,028 - mmcv - INFO - \n",
            "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,030 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,031 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,032 - mmcv - INFO - \n",
            "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,034 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,035 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,037 - mmcv - INFO - \n",
            "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,038 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,039 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,041 - mmcv - INFO - \n",
            "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,042 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,044 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,045 - mmcv - INFO - \n",
            "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,046 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,048 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,049 - mmcv - INFO - \n",
            "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,050 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,052 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,053 - mmcv - INFO - \n",
            "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,054 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,055 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,056 - mmcv - INFO - \n",
            "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,058 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,059 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,061 - mmcv - INFO - \n",
            "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,062 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,064 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,065 - mmcv - INFO - \n",
            "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,066 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,068 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,069 - mmcv - INFO - \n",
            "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,070 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,072 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,073 - mmcv - INFO - \n",
            "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,074 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,076 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,077 - mmcv - INFO - \n",
            "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,078 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,080 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,081 - mmcv - INFO - \n",
            "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,083 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,084 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,086 - mmcv - INFO - \n",
            "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,087 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,088 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,090 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,095 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,096 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,099 - mmcv - INFO - \n",
            "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,101 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,102 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,103 - mmcv - INFO - \n",
            "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,106 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,108 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,109 - mmcv - INFO - \n",
            "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,111 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,113 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,115 - mmcv - INFO - \n",
            "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,117 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,119 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,121 - mmcv - INFO - \n",
            "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,122 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,124 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,126 - mmcv - INFO - \n",
            "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,128 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,130 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2022-06-13 18:39:13,131 - mmcv - INFO - \n",
            "neck.convs.0.conv.weight - torch.Size([512, 2048, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,133 - mmcv - INFO - \n",
            "neck.convs.0.conv.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,135 - mmcv - INFO - \n",
            "rpn_head.rpn_conv.weight - torch.Size([512, 512, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,137 - mmcv - INFO - \n",
            "rpn_head.rpn_conv.bias - torch.Size([512]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,139 - mmcv - INFO - \n",
            "rpn_head.rpn_cls.weight - torch.Size([12, 512, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,141 - mmcv - INFO - \n",
            "rpn_head.rpn_cls.bias - torch.Size([12]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,143 - mmcv - INFO - \n",
            "rpn_head.rpn_reg.weight - torch.Size([48, 512, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,144 - mmcv - INFO - \n",
            "rpn_head.rpn_reg.bias - torch.Size([48]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,146 - mmcv - INFO - \n",
            "roi_head.bbox_roi_extractor.embed_network.conv.weight - torch.Size([512, 512, 3, 3]): \n",
            "Initialized by user-defined `init_weights` in ConvModule  \n",
            " \n",
            "2022-06-13 18:39:13,148 - mmcv - INFO - \n",
            "roi_head.bbox_roi_extractor.embed_network.conv.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,150 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_cls.weight - torch.Size([2, 1024]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,152 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_cls.bias - torch.Size([2]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,154 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,156 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_reg.bias - torch.Size([4]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,157 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 25088]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,159 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,161 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,163 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,165 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.2.weight - torch.Size([1024, 1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,167 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.2.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2022-06-13 18:39:13,169 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,170 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,172 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.ref_fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,176 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.ref_fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,177 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,182 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,183 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.ref_fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,184 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.0.ref_fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,185 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,188 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,189 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.ref_fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,191 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.ref_fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,195 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,197 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,198 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.ref_fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,199 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.1.ref_fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,200 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,204 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,206 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.ref_fc_embed.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,207 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.ref_fc_embed.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,211 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,213 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,214 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.ref_fc.weight - torch.Size([1024, 1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2022-06-13 18:39:13,215 - mmcv - INFO - \n",
            "roi_head.bbox_head.aggregator.2.ref_fc.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n"
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "from mmtrack.datasets import build_dataset\n",
        "from mmdet.apis import train_detector as train_model\n",
        "from mmdet.models import build_detector as build_model\n",
        "from mmtrack.models.roi_heads import SelsaRoIHead\n",
        "\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "model = build_model(cfg.model.detector)\n",
        "model.init_weights()"
      ],
      "id": "889b4255-50be-4da3-85c4-dcd19c8111ac"
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) OpenMMLab. All rights reserved.\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from mmcv.runner import (DistSamplerSeedHook, EpochBasedRunner,\n",
        "                         Fp16OptimizerHook, OptimizerHook, build_runner,\n",
        "                         get_dist_info)\n",
        "\n",
        "from mmdet.core import DistEvalHook, EvalHook, build_optimizer\n",
        "from mmdet.datasets import (build_dataloader, build_dataset,\n",
        "                            replace_ImageToTensor)\n",
        "from mmdet.utils import (build_ddp, build_dp, compat_cfg,\n",
        "                         find_latest_checkpoint, get_root_logger)\n",
        "\n",
        "\n",
        "def init_random_seed(seed=None, device='cuda'):\n",
        "    \"\"\"Initialize random seed.\n",
        "\n",
        "    If the seed is not set, the seed will be automatically randomized,\n",
        "    and then broadcast to all processes to prevent some potential bugs.\n",
        "\n",
        "    Args:\n",
        "        seed (int, Optional): The seed. Default to None.\n",
        "        device (str): The device where the seed will be put on.\n",
        "            Default to 'cuda'.\n",
        "\n",
        "    Returns:\n",
        "        int: Seed to be used.\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        return seed\n",
        "\n",
        "    # Make sure all ranks share the same random seed to prevent\n",
        "    # some potential bugs. Please refer to\n",
        "    # https://github.com/open-mmlab/mmdetection/issues/6339\n",
        "    rank, world_size = get_dist_info()\n",
        "    seed = np.random.randint(2**31)\n",
        "    if world_size == 1:\n",
        "        return seed\n",
        "\n",
        "    if rank == 0:\n",
        "        random_num = torch.tensor(seed, dtype=torch.int32, device=device)\n",
        "    else:\n",
        "        random_num = torch.tensor(0, dtype=torch.int32, device=device)\n",
        "    dist.broadcast(random_num, src=0)\n",
        "    return random_num.item()\n",
        "\n",
        "\n",
        "def set_random_seed(seed, deterministic=False):\n",
        "    \"\"\"Set random seed.\n",
        "\n",
        "    Args:\n",
        "        seed (int): Seed to be used.\n",
        "        deterministic (bool): Whether to set the deterministic option for\n",
        "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
        "            to True and `torch.backends.cudnn.benchmark` to False.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def auto_scale_lr(cfg, distributed, logger):\n",
        "    \"\"\"Automatically scaling LR according to GPU number and sample per GPU.\n",
        "\n",
        "    Args:\n",
        "        cfg (config): Training config.\n",
        "        distributed (bool): Using distributed or not.\n",
        "        logger (logging.Logger): Logger.\n",
        "    \"\"\"\n",
        "    # Get flag from config\n",
        "    if ('auto_scale_lr' not in cfg) or \\\n",
        "            (not cfg.auto_scale_lr.get('enable', False)):\n",
        "        logger.info('Automatic scaling of learning rate (LR)'\n",
        "                    ' has been disabled.')\n",
        "        return\n",
        "\n",
        "    # Get base batch size from config\n",
        "    base_batch_size = cfg.auto_scale_lr.get('base_batch_size', None)\n",
        "    if base_batch_size is None:\n",
        "        return\n",
        "\n",
        "    # Get gpu number\n",
        "    if distributed:\n",
        "        _, world_size = get_dist_info()\n",
        "        num_gpus = len(range(world_size))\n",
        "    else:\n",
        "        num_gpus = len(cfg.gpu_ids)\n",
        "\n",
        "    # calculate the batch size\n",
        "    samples_per_gpu = cfg.data.train_dataloader.samples_per_gpu\n",
        "    batch_size = num_gpus * samples_per_gpu\n",
        "    logger.info(f'Training with {num_gpus} GPU(s) with {samples_per_gpu} '\n",
        "                f'samples per GPU. The total batch size is {batch_size}.')\n",
        "\n",
        "    if batch_size != base_batch_size:\n",
        "        # scale LR with\n",
        "        # [linear scaling rule](https://arxiv.org/abs/1706.02677)\n",
        "        scaled_lr = (batch_size / base_batch_size) * cfg.optimizer.lr\n",
        "        logger.info('LR has been automatically scaled '\n",
        "                    f'from {cfg.optimizer.lr} to {scaled_lr}')\n",
        "        cfg.optimizer.lr = scaled_lr\n",
        "    else:\n",
        "        logger.info('The batch size match the '\n",
        "                    f'base batch size: {base_batch_size}, '\n",
        "                    f'will not scaling the LR ({cfg.optimizer.lr}).')\n",
        "\n",
        "\n",
        "def train_detector(model,\n",
        "                   dataset,\n",
        "                   cfg,\n",
        "                   distributed=False,\n",
        "                   validate=False,\n",
        "                   timestamp=None,\n",
        "                   meta=None):\n",
        "\n",
        "    cfg = compat_cfg(cfg)\n",
        "    logger = get_root_logger(log_level=cfg.log_level)\n",
        "\n",
        "    # prepare data loaders\n",
        "    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n",
        "\n",
        "    runner_type = 'EpochBasedRunner' if 'runner' not in cfg else cfg.runner[\n",
        "        'type']\n",
        "\n",
        "    train_dataloader_default_args = dict(\n",
        "        samples_per_gpu=2,\n",
        "        workers_per_gpu=2,\n",
        "        # `num_gpus` will be ignored if distributed\n",
        "        num_gpus=len(cfg.gpu_ids),\n",
        "        dist=distributed,\n",
        "        seed=cfg.seed,\n",
        "        runner_type=runner_type,\n",
        "        persistent_workers=False)\n",
        "\n",
        "    train_loader_cfg = {\n",
        "        **train_dataloader_default_args,\n",
        "        **cfg.data.get('train_dataloader', {})\n",
        "    }\n",
        "\n",
        "    data_loaders = [build_dataloader(ds, **train_loader_cfg) for ds in dataset]\n",
        "\n",
        "    # put model on gpus\n",
        "    if distributed:\n",
        "        find_unused_parameters = cfg.get('find_unused_parameters', False)\n",
        "        # Sets the `find_unused_parameters` parameter in\n",
        "        # torch.nn.parallel.DistributedDataParallel\n",
        "        model = build_ddp(\n",
        "            model,\n",
        "            cfg.device,\n",
        "            device_ids=[int(os.environ['LOCAL_RANK'])],\n",
        "            broadcast_buffers=False,\n",
        "            find_unused_parameters=find_unused_parameters)\n",
        "    else:\n",
        "        model = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
        "\n",
        "    # build optimizer\n",
        "    auto_scale_lr(cfg, distributed, logger)\n",
        "    optimizer = build_optimizer(model, cfg.optimizer)\n",
        "\n",
        "    runner = build_runner(\n",
        "        cfg.runner,\n",
        "        default_args=dict(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            work_dir=cfg.work_dir,\n",
        "            logger=logger,\n",
        "            meta=meta))\n",
        "\n",
        "    # an ugly workaround to make .log and .log.json filenames the same\n",
        "    runner.timestamp = timestamp\n",
        "\n",
        "    # fp16 setting\n",
        "    fp16_cfg = cfg.get('fp16', None)\n",
        "    if fp16_cfg is not None:\n",
        "        optimizer_config = Fp16OptimizerHook(\n",
        "            **cfg.optimizer_config, **fp16_cfg, distributed=distributed)\n",
        "    elif distributed and 'type' not in cfg.optimizer_config:\n",
        "        optimizer_config = OptimizerHook(**cfg.optimizer_config)\n",
        "    else:\n",
        "        optimizer_config = cfg.optimizer_config\n",
        "\n",
        "    # register hooks\n",
        "    runner.register_training_hooks(\n",
        "        cfg.lr_config,\n",
        "        optimizer_config,\n",
        "        cfg.checkpoint_config,\n",
        "        cfg.log_config,\n",
        "        cfg.get('momentum_config', None),\n",
        "        custom_hooks_config=cfg.get('custom_hooks', None))\n",
        "\n",
        "    if distributed:\n",
        "        if isinstance(runner, EpochBasedRunner):\n",
        "            runner.register_hook(DistSamplerSeedHook())\n",
        "\n",
        "    # register eval hooks\n",
        "    if validate:\n",
        "        val_dataloader_default_args = dict(\n",
        "            samples_per_gpu=1,\n",
        "            workers_per_gpu=2,\n",
        "            dist=distributed,\n",
        "            shuffle=False,\n",
        "            persistent_workers=False)\n",
        "\n",
        "        val_dataloader_args = {\n",
        "            **val_dataloader_default_args,\n",
        "            **cfg.data.get('val_dataloader', {})\n",
        "        }\n",
        "        # Support batch_size > 1 in validation\n",
        "\n",
        "        if val_dataloader_args['samples_per_gpu'] > 1:\n",
        "            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
        "            cfg.data.val.pipeline = replace_ImageToTensor(\n",
        "                cfg.data.val.pipeline)\n",
        "        val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n",
        "\n",
        "        val_dataloader = build_dataloader(val_dataset, **val_dataloader_args)\n",
        "        eval_cfg = cfg.get('evaluation', {})\n",
        "        eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'\n",
        "        eval_hook = DistEvalHook if distributed else EvalHook\n",
        "        # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the\n",
        "        # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.\n",
        "        runner.register_hook(\n",
        "            eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n",
        "\n",
        "    resume_from = None\n",
        "    if cfg.resume_from is None and cfg.get('auto_resume'):\n",
        "        resume_from = find_latest_checkpoint(cfg.work_dir)\n",
        "    if resume_from is not None:\n",
        "        cfg.resume_from = resume_from\n",
        "\n",
        "    if cfg.resume_from:\n",
        "        runner.resume(cfg.resume_from)\n",
        "    elif cfg.load_from:\n",
        "        runner.load_checkpoint(cfg.load_from)\n",
        "    \n",
        "    print(list(data_loaders))\n",
        "    runner.run(data_loaders, cfg.workflow)\n"
      ],
      "metadata": {
        "id": "K92CXQupY9XT"
      },
      "id": "K92CXQupY9XT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f7NsUUu_MWH3"
      },
      "id": "f7NsUUu_MWH3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9RjtFDGKSdYq",
        "outputId": "21aa0c93-c85c-4569-80c3-cd8327aee93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmtracking/mmtrack/datasets/pipelines/formatting.py:138: UserWarning: The 'ConcatVideoReferences' class will be deprecated in the future, please use 'ConcatSameTypeFrames' instead\n",
            "  \"The 'ConcatVideoReferences' class will be deprecated in the \"\n",
            "/usr/local/lib/python3.7/dist-packages/mmdet/utils/compat_config.py:30: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
            "  'please set `runner` in your config.', UserWarning)\n",
            "2022-06-13 19:20:58,708 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2022-06-13 19:20:58,711 - mmdet - INFO - Start running, host: root@fc42d8f337e8, work_dir: /content/mmtracking/tutorial_exps/detector\n",
            "2022-06-13 19:20:58,714 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2022-06-13 19:20:58,717 - mmdet - INFO - workflow: [('train', 1)], max: 7 epochs\n",
            "2022-06-13 19:20:58,720 - mmdet - INFO - Checkpoints will be saved to /content/mmtracking/tutorial_exps/detector by HardDiskBackend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done (t=20.58s)\n",
            "creating index...\n",
            "index created!\n",
            "['nerve']\n",
            "[<torch.utils.data.dataloader.DataLoader object at 0x7f7d27d12810>]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-b3b8472c9240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-eb19cce703cb>\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/mmdet/datasets/custom.py\", line 218, in __getitem__\n    data = self.prepare_train_img(idx)\n  File \"/content/mmtracking/mmtrack/datasets/coco_video_dataset.py\", line 282, in prepare_train_img\n    return self.prepare_data(idx)\n  File \"/content/mmtracking/mmtrack/datasets/coco_video_dataset.py\", line 270, in prepare_data\n    return self.pipeline(results)\n  File \"/usr/local/lib/python3.7/dist-packages/mmdet/datasets/pipelines/compose.py\", line 41, in __call__\n    data = t(data)\n  File \"/content/mmtracking/mmtrack/datasets/pipelines/loading.py\", line 34, in __call__\n    _results = super().__call__(_results)\n  File \"/usr/local/lib/python3.7/dist-packages/mmdet/datasets/pipelines/loading.py\", line 61, in __call__\n    if results['img_prefix'] is not None:\nTypeError: string indices must be integers\n"
          ]
        }
      ],
      "source": [
        "datasets = [build_dataset(cfg.data.train)]\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "print(model.CLASSES)\n",
        "train_detector(model, datasets, cfg)"
      ],
      "id": "9RjtFDGKSdYq"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ab2c382c-a169-46fe-938f-c6687d763e8e",
        "e7bd4f44-447a-49a5-8c9c-cf160691bda5"
      ],
      "name": "Temporal ROI Align.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}